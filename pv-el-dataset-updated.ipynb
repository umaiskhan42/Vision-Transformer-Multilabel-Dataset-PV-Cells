{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ac803",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-19T14:30:19.975878Z",
     "iopub.status.busy": "2025-02-19T14:30:19.975607Z",
     "iopub.status.idle": "2025-02-19T14:30:28.570610Z",
     "shell.execute_reply": "2025-02-19T14:30:28.569523Z"
    },
    "papermill": {
     "duration": 8.601822,
     "end_time": "2025-02-19T14:30:28.572034",
     "exception": false,
     "start_time": "2025-02-19T14:30:19.970212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install vit-keras\n",
    "%pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173f954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:30:40.318433Z",
     "iopub.status.busy": "2025-02-19T14:30:40.318007Z",
     "iopub.status.idle": "2025-02-19T14:30:41.433414Z",
     "shell.execute_reply": "2025-02-19T14:30:41.432484Z"
    },
    "papermill": {
     "duration": 1.122519,
     "end_time": "2025-02-19T14:30:41.435083",
     "exception": false,
     "start_time": "2025-02-19T14:30:40.312564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285a106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:30:41.446194Z",
     "iopub.status.busy": "2025-02-19T14:30:41.445758Z",
     "iopub.status.idle": "2025-02-19T14:30:41.449144Z",
     "shell.execute_reply": "2025-02-19T14:30:41.448490Z"
    },
    "papermill": {
     "duration": 0.010046,
     "end_time": "2025-02-19T14:30:41.450330",
     "exception": false,
     "start_time": "2025-02-19T14:30:41.440284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "labels_test = []\n",
    "\n",
    "path_train = []\n",
    "path_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb05e76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:30:41.460298Z",
     "iopub.status.busy": "2025-02-19T14:30:41.460100Z",
     "iopub.status.idle": "2025-02-19T14:30:41.463090Z",
     "shell.execute_reply": "2025-02-19T14:30:41.462450Z"
    },
    "papermill": {
     "duration": 0.009246,
     "end_time": "2025-02-19T14:30:41.464263",
     "exception": false,
     "start_time": "2025-02-19T14:30:41.455017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = r\"solar_cell_EL_image\\PVELAD\\EL2021\\trainval\\JPEGImages\"\n",
    "test_path = r\"solar_cell_EL_image\\PVELAD\\EL2021\\test\\JPEGImages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee085c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:30:41.474374Z",
     "iopub.status.busy": "2025-02-19T14:30:41.474177Z",
     "iopub.status.idle": "2025-02-19T14:31:06.696294Z",
     "shell.execute_reply": "2025-02-19T14:31:06.695274Z"
    },
    "papermill": {
     "duration": 25.22859,
     "end_time": "2025-02-19T14:31:06.697682",
     "exception": false,
     "start_time": "2025-02-19T14:30:41.469092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Paths\n",
    "train_path = r\"solar_cell_EL_image\\PVELAD\\EL2021\\trainval\\JPEGImages\"\n",
    "annotations_dir = r\"solar_cell_EL_image\\PVELAD\\EL2021\\trainval\\Annotations\"\n",
    "\n",
    "# Lists to store data\n",
    "labels_train = []\n",
    "path_train = []\n",
    "\n",
    "def extract_labels_from_xml(xml_file_path):\n",
    "    \"\"\"Extract object labels from an XML annotation file.\"\"\"\n",
    "    if not os.path.exists(xml_file_path):\n",
    "        return []  # If XML file does not exist, return empty list\n",
    "    \n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    return [obj.find('name').text for obj in root.findall('object')]\n",
    "\n",
    "# Iterate through images and extract labels\n",
    "for filename in os.listdir(train_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        xml_file_path = os.path.join(annotations_dir, filename.replace('.jpg', '.xml'))\n",
    "        labels = extract_labels_from_xml(xml_file_path)\n",
    "\n",
    "        labels_train.append(labels)\n",
    "        path_train.append(os.path.join(train_path, filename))\n",
    "\n",
    "# Apply MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_train_bin = mlb.fit_transform(labels_train)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(labels_train_bin, columns=mlb.classes_)\n",
    "df.insert(0, \"image_path\", path_train)  # Add image path as first column\n",
    "\n",
    "# Save to CSV\n",
    "csv_output_path = \"1multilabel_annotations.csv\"\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "\n",
    "print(f\"Saved multi-label annotations to {csv_output_path}\")\n",
    "print(df.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8441454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:31:06.708562Z",
     "iopub.status.busy": "2025-02-19T14:31:06.708332Z",
     "iopub.status.idle": "2025-02-19T14:31:06.711796Z",
     "shell.execute_reply": "2025-02-19T14:31:06.710846Z"
    },
    "papermill": {
     "duration": 0.010104,
     "end_time": "2025-02-19T14:31:06.713047",
     "exception": false,
     "start_time": "2025-02-19T14:31:06.702943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "\n",
    "from transformers import ViTFeatureExtractor, TFAutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load model & feature extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "model = TFAutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert(\"RGB\").resize((224, 224))\n",
    "    return np.array(img)\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name=\"vit.encoder.layer.11.output\"):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.model.input],\n",
    "        [model.model.get_layer(last_conv_layer_name).output, model.model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, tf.argmax(predictions[0])]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) / tf.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def overlay_heatmap(heatmap, image, alpha=0.4):\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = heatmap_color * alpha + image\n",
    "    return np.uint8(superimposed_img)\n",
    "\n",
    "# Upload and process\n",
    "image_paths = [\"Picture1.png\", \"Picture2.png\", \"Picture3.png\"]\n",
    "for path in image_paths:\n",
    "    raw_img = load_image(path)\n",
    "    inputs = feature_extractor(images=raw_img, return_tensors=\"tf\")\n",
    "    heatmap = make_gradcam_heatmap(inputs[\"pixel_values\"], model)\n",
    "    overlay_img = overlay_heatmap(heatmap, raw_img)\n",
    "    Image.fromarray(overlay_img).save(\"gradcam_\" + path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349a685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:31:06.723850Z",
     "iopub.status.busy": "2025-02-19T14:31:06.723594Z",
     "iopub.status.idle": "2025-02-19T14:32:21.750417Z",
     "shell.execute_reply": "2025-02-19T14:32:21.749427Z"
    },
    "papermill": {
     "duration": 75.038314,
     "end_time": "2025-02-19T14:32:21.756498",
     "exception": false,
     "start_time": "2025-02-19T14:31:06.718184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)  # Load image using OpenCV\n",
    "        img = cv2.resize(img, (desired_width, desired_height))  # Resize image\n",
    "        img = img.astype(np.float32) / 255.0  # Normalize pixel values\n",
    "        images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Define desired width and height for resizing images\n",
    "desired_width = 224\n",
    "desired_height = 224\n",
    "\n",
    "# Load and preprocess images\n",
    "x_train = load_and_preprocess_images(path_train)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, labels_train_bin, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_val shape:\", x_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b5f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:32:21.767348Z",
     "iopub.status.busy": "2025-02-19T14:32:21.767108Z",
     "iopub.status.idle": "2025-02-19T14:32:22.391885Z",
     "shell.execute_reply": "2025-02-19T14:32:22.390984Z"
    },
    "papermill": {
     "duration": 0.631748,
     "end_time": "2025-02-19T14:32:22.393309",
     "exception": false,
     "start_time": "2025-02-19T14:32:21.761561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Restart the kernel after installing/uninstalling TensorFlow before running this cell!\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow can access GPUs\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpu_devices:\n",
    "    print(\"Found GPU(s):\")\n",
    "    for gpu in gpu_devices:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU(s) found. TensorFlow will use CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bdf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.14.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall tensorflow-addons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb2020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:32:22.404407Z",
     "iopub.status.busy": "2025-02-19T14:32:22.404182Z",
     "iopub.status.idle": "2025-02-19T14:32:22.728985Z",
     "shell.execute_reply": "2025-02-19T14:32:22.727815Z"
    },
    "papermill": {
     "duration": 0.331505,
     "end_time": "2025-02-19T14:32:22.730168",
     "exception": true,
     "start_time": "2025-02-19T14:32:22.398663",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vit_keras import vit\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Load ViT model\n",
    "vit_model = vit.vit_b16(\n",
    "    image_size=224,\n",
    "    activation=\"sigmoid\",\n",
    "    pretrained=False,\n",
    "    include_top=True,\n",
    "    pretrained_top=False,\n",
    "    classes=12\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "vit_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\"ViT_best_weights.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# vit_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44976a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T13:53:18.750861Z",
     "iopub.status.busy": "2025-02-19T13:53:18.750561Z",
     "iopub.status.idle": "2025-02-19T14:01:11.787713Z",
     "shell.execute_reply": "2025-02-19T14:01:11.786877Z",
     "shell.execute_reply.started": "2025-02-19T13:53:18.750840Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "history = vit_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "pd.DataFrame(history.history).to_csv(\"ViT_training_history.csv\", index=False)\n",
    "print(\"ViT training completed and history saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30001dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:10:10.332641Z",
     "iopub.status.busy": "2025-02-19T14:10:10.332330Z",
     "iopub.status.idle": "2025-02-19T14:10:11.565184Z",
     "shell.execute_reply": "2025-02-19T14:10:11.564291Z",
     "shell.execute_reply.started": "2025-02-19T14:10:10.332619Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    # Extract data from history object\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b-o', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-o', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.ylim(0, 1)  # Set y-axis limits for accuracy\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b-o', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    max_loss = max(max(loss), max(val_loss))\n",
    "    plt.ylim(0, 0.5)  # Set y-axis limits for accuracy\n",
    "    #plt.ylim(0, max_loss + 0.1 * max_loss)  # Set y-axis limits for loss with padding\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_training_history(history, save_path='vit_training_history.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5cd32e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:19:30.111335Z",
     "iopub.status.busy": "2025-02-19T14:19:30.110936Z",
     "iopub.status.idle": "2025-02-19T14:19:31.655512Z",
     "shell.execute_reply": "2025-02-19T14:19:31.654540Z",
     "shell.execute_reply.started": "2025-02-19T14:19:30.111306Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Load the MobileNetV2 model with pre-trained ImageNet weights, excluding the top layer\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(12, activation='sigmoid')(x)  # Assuming 12 classes with multi-label classification\n",
    "\n",
    "# Create the complete model\n",
    "mobilenet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "mobilenet_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('MobileNetV2_best_weights.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# mobilenet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adf198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:19:34.898895Z",
     "iopub.status.busy": "2025-02-19T14:19:34.898554Z",
     "iopub.status.idle": "2025-02-19T14:20:43.527223Z",
     "shell.execute_reply": "2025-02-19T14:20:43.526282Z",
     "shell.execute_reply.started": "2025-02-19T14:19:34.898866Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "history_mn = mobilenet_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "pd.DataFrame(history.history).to_csv(\"Mobilenet_training_history.csv\", index=False)\n",
    "print(\"ViT training completed and history saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2a86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:20:43.528673Z",
     "iopub.status.busy": "2025-02-19T14:20:43.528421Z",
     "iopub.status.idle": "2025-02-19T14:20:46.552848Z",
     "shell.execute_reply": "2025-02-19T14:20:46.551925Z",
     "shell.execute_reply.started": "2025-02-19T14:20:43.528650Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    # Extract data from history object\n",
    "    acc = history_mn.history['accuracy']\n",
    "    val_acc = history_mn.history['val_accuracy']\n",
    "    loss = history_mn.history['loss']\n",
    "    val_loss = history_mn.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b-o', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-o', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.ylim(0, 1)  # Set y-axis limits for accuracy\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b-o', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    max_loss = max(max(loss), max(val_loss))\n",
    "    plt.ylim(0, 0.5)  # Set y-axis limits for accuracy\n",
    "    #plt.ylim(0, max_loss + 0.1 * max_loss)  # Set y-axis limits for loss with padding\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_training_history(history, save_path='mn_training_history.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0511978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:20:46.554854Z",
     "iopub.status.busy": "2025-02-19T14:20:46.554627Z",
     "iopub.status.idle": "2025-02-19T14:20:48.920641Z",
     "shell.execute_reply": "2025-02-19T14:20:48.919920Z",
     "shell.execute_reply.started": "2025-02-19T14:20:46.554834Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Load the ResNet50 model with pre-trained ImageNet weights, excluding the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(12, activation='sigmoid')(x)  # Assuming 12 classes with multi-label classification\n",
    "\n",
    "# Create the complete model\n",
    "resnet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "resnet_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('ResNet50_best_weights.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353e845",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:20:48.922024Z",
     "iopub.status.busy": "2025-02-19T14:20:48.921793Z",
     "iopub.status.idle": "2025-02-19T14:22:37.799443Z",
     "shell.execute_reply": "2025-02-19T14:22:37.798597Z",
     "shell.execute_reply.started": "2025-02-19T14:20:48.922004Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "history_rs = resnet_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "pd.DataFrame(history.history).to_csv(\"Resnet_training_history.csv\", index=False)\n",
    "print(\"Resnet training completed and history saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8668477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:22:37.800596Z",
     "iopub.status.busy": "2025-02-19T14:22:37.800297Z",
     "iopub.status.idle": "2025-02-19T14:22:39.089849Z",
     "shell.execute_reply": "2025-02-19T14:22:39.088966Z",
     "shell.execute_reply.started": "2025-02-19T14:22:37.800572Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    # Extract data from history object\n",
    "    acc = history_rs.history['accuracy']\n",
    "    val_acc = history_rs.history['val_accuracy']\n",
    "    loss = history_rs.history['loss']\n",
    "    val_loss = history_rs.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b-o', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-o', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.ylim(0, 1)  # Set y-axis limits for accuracy\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b-o', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    max_loss = max(max(loss), max(val_loss))\n",
    "    plt.ylim(0, 0.5)  # Set y-axis limits for accuracy\n",
    "    #plt.ylim(0, max_loss + 0.1 * max_loss)  # Set y-axis limits for loss with padding\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_training_history(history, save_path='rs_training_history.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681547c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:22:39.091399Z",
     "iopub.status.busy": "2025-02-19T14:22:39.091021Z",
     "iopub.status.idle": "2025-02-19T14:22:41.321162Z",
     "shell.execute_reply": "2025-02-19T14:22:41.320484Z",
     "shell.execute_reply.started": "2025-02-19T14:22:39.091363Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Load the EfficientNetB0 model with pre-trained ImageNet weights, excluding the top layer\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Dense(12, activation='sigmoid')(x)  # Assuming 12 classes with multi-label classification\n",
    "\n",
    "# Create the complete model\n",
    "efficientnet_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "efficientnet_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint('EfficientNetB0_best_weights.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "\n",
    "# efficientnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361984a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:22:41.322137Z",
     "iopub.status.busy": "2025-02-19T14:22:41.321895Z",
     "iopub.status.idle": "2025-02-19T14:24:33.979327Z",
     "shell.execute_reply": "2025-02-19T14:24:33.978513Z",
     "shell.execute_reply.started": "2025-02-19T14:22:41.322116Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train\n",
    "history_ef = efficientnet_model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "pd.DataFrame(history.history).to_csv(\"EF_training_history.csv\", index=False)\n",
    "print(\"EF training completed and history saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e9eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T14:24:33.981110Z",
     "iopub.status.busy": "2025-02-19T14:24:33.980876Z",
     "iopub.status.idle": "2025-02-19T14:24:35.247320Z",
     "shell.execute_reply": "2025-02-19T14:24:35.246318Z",
     "shell.execute_reply.started": "2025-02-19T14:24:33.981091Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    # Extract data from history object\n",
    "    acc = history_ef.history['accuracy']\n",
    "    val_acc = history_ef.history['val_accuracy']\n",
    "    loss = history_ef.history['loss']\n",
    "    val_loss = history_ef.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b-o', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r-o', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Accuracy', fontsize=14)\n",
    "    plt.ylim(0, 1)  # Set y-axis limits for accuracy\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b-o', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r-o', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss', fontsize=16)\n",
    "    plt.xlabel('Epochs', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "    max_loss = max(max(loss), max(val_loss))\n",
    "    plt.ylim(0, 0.5)  # Set y-axis limits for accuracy\n",
    "    #plt.ylim(0, max_loss + 0.1 * max_loss)  # Set y-axis limits for loss with padding\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_training_history(history, save_path='ef_training_history.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487cc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Example usage (replace with your model/image/layer)\n",
    "# img_tensor = np.expand_dims(img, axis=0)\n",
    "# heatmap = make_gradcam_heatmap(img_tensor, model, 'last_conv_layer_name')\n",
    "# plt.matshow(heatmap)\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4958474,
     "sourceId": 8346804,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 127.789703,
   "end_time": "2025-02-19T14:32:25.217938",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-19T14:30:17.428235",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
